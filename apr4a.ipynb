{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans1\n",
    "A decision tree classifier is a supervised machine learning algorithm used for both classification and regression tasks. The algorithm builds a tree-like structure where each internal node represents a decision based on a feature, each branch represents an outcome of the decision, and each leaf node represents the final prediction.To make predictions, a new data point traverses the tree from the root to a leaf node based on the feature values of the data point. The predicted class or value associated with that leaf node is then assigned to the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans2\n",
    "The mathematical intuition behind decision tree classification involves determining the best feature and threshold to split the data at each node. The decision is made by maximizing a criterion, usually information gain or Gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans3\n",
    "In a binary classification problem, a decision tree classifier assigns each instance to one of two classes (positive or negative). The tree is built by recursively splitting the dataset based on features and thresholds. The process continues until the stopping criteria are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans4\n",
    "The geometric intuition behind decision tree classification involves partitioning the feature space into regions, with each region corresponding to a different class. Each split in the tree can be seen as a decision boundary in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans5\n",
    "A confusion matrix is a table that summarizes the performance of a classification algorithm. It compares the predicted class labels with the actual class labels and consists of four entries:\n",
    "\n",
    "True Positive (TP): Instances correctly predicted as positive.\n",
    "True Negative (TN): Instances correctly predicted as negative.\n",
    "False Positive (FP): Instances incorrectly predicted as positive.\n",
    "False Negative (FN): Instances incorrectly predicted as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans7\n",
    "Choosing an appropriate evaluation metric is crucial as different metrics highlight different aspects of a model's performance. The choice depends on the specific goals and requirements of the problem.\n",
    "Accuracy: Suitable when classes are balanced.\n",
    "Precision: Emphasizes the importance of avoiding false positives.\n",
    "Recall: Emphasizes the importance of detecting all positive instances.\n",
    "F1 Score: Balances precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans8\n",
    "In email spam detection, precision is crucial. False positives (classifying a non-spam email as spam) can be highly disruptive and annoying to users. Users may lose important emails if false positives are frequent. Therefore, in such a scenario, precision is more important than recall, as the focus is on minimizing the number of false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans9\n",
    "In a medical diagnosis system for a life-threatening disease, recall is more critical. Missing a positive case (false negative) could have severe consequences, and it's more acceptable to have some false positives. Maximizing recall ensures that as many true positive cases as possible are identified, even if it means tolerating a higher number of false positives."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
