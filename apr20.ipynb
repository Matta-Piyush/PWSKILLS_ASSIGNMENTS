{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans1\n",
    "KNN (k-Nearest Neighbors) is a supervised machine learning algorithm used for both classification and regression tasks. In KNN, a data point is classified or predicted based on the majority class or average of the k-nearest data points in the feature space. The \"k\" in KNN represents the number of neighbors considered for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans2\n",
    "Common methods for choosing the value of k include:\n",
    "\n",
    "Trying different odd values of k.\n",
    "Using cross-validation to find the optimal k by evaluating performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans3\n",
    "KNN Classifier: In classification, KNN assigns a data point to the majority class among its k-nearest neighbors.\n",
    "\n",
    "KNN Regressor: In regression, KNN predicts the target variable by taking the average (or weighted average) of the target values of its k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans4\n",
    "The performance of KNN is measured using appropriate metrics based on the task:\n",
    "\n",
    "Classification:\n",
    "Accuracy, precision, recall, F1-score, confusion matrix.\n",
    "Area under the Receiver Operating Characteristic (ROC) curve for binary classification.\n",
    "Regression:\n",
    "Mean Squared Error (MSE), Mean Absolute Error (MAE), R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans5\n",
    "The curse of dimensionality refers to the phenomenon where the performance of KNN deteriorates as the number of dimensions (features) increases. In high-dimensional spaces, the distance between data points becomes less meaningful, and the majority of data points are equally far away. This makes it challenging for KNN to identify relevant neighbors, leading to a decline in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans6\n",
    "KNN can handle missing values by imputing them based on the values of their nearest neighbors. The process involves finding the k-nearest neighbors of the data point with missing values and imputing the missing values using the average or weighted average of the neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans7\n",
    "KNN Classifier:\n",
    "\n",
    "Suitable for classification problems.\n",
    "Decision based on majority class.\n",
    "Appropriate for cases where the decision boundary is non-linear.\n",
    "KNN Regressor:\n",
    "\n",
    "Suitable for regression problems.\n",
    "Decision based on the average (or weighted average) of neighbors' target values.\n",
    "Effective when relationships are non-linear and local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans8\n",
    "Strengths:\n",
    "\n",
    "Simple and easy to understand.\n",
    "No assumption about the underlying data distribution.\n",
    "Effective in capturing non-linear relationships.\n",
    "Weaknesses:\n",
    "\n",
    "Sensitive to irrelevant or redundant features.\n",
    "Computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans10\n",
    "Feature scaling is essential in KNN because the algorithm relies on the distance between data points to make predictions. If features have different scales, the impact of a feature with a larger scale on the distance calculation will be larger, potentially dominating the contribution of features with smaller scales."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
